{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing tabular PLSS data with Python "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is available here: https://github.com/MD-Troyer/blog-notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating raw PLSS data for a polygon is pretty trivial. A simple spatial intersection with a plss grid in ArcMap will do the trick. What we would typically like however, is that list of Twn/Rng/Sec/QQ1/QQ2 data consolidated according to completely represented units. For example, if we have all 16 quarter-quarters for a single section, we would like to represent that as a single row [as 'entire section'] rather than listing all 16 QQ rows individually. Similarly, if we have all 4 quarter-quarters for a single quarter section, we would like to represent that as a single row [as 'entire quarter'] rather than listing all 4 Q rows individually.\n",
    "\n",
    "The following illustrates how to to compress PLSS data in this way with Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \\\n",
    "    r'C:\\Users\\michael\\Documents\\_projects\\compress-plss\\compress-plss.csv'\n",
    "\n",
    "# We will use a default dictionary init with an empty list to sort the rows\n",
    "plss = defaultdict(list)\n",
    "\n",
    "# Read the csv, row-by-row, skip the header\n",
    "reader = csv.reader(open(csv_path, 'r'))\n",
    "# Skip the header row\n",
    "reader.next()\n",
    "\n",
    "source_rows = []\n",
    "\n",
    "# Source table format:\n",
    "# | PM | Twn | Rng | QQ1 | QQ2 |\n",
    "    \n",
    "# For each row\n",
    "for row in reader:\n",
    "    # Keep the source rows for comparison\n",
    "    source_rows.append(row)\n",
    "    try:\n",
    "        # Get the PM/Twn/Rng/Sec \n",
    "        pm  = row[0]; twn = row[1]; rng = row[2]; sec = row[3]\n",
    "        # Pass to defaultdict with concatenated PM-TWN-RNG-SEC as key\n",
    "        # and a tuple of (QQ1, QQ2) as the value -> into the empty list\n",
    "        # If key does not exist, create it, else append (QQ1, QQ2) to list\n",
    "        plss[pm +'-'+ twn +'-'+ rng +'-'+ sec].append([row[4], row[5]])\n",
    "    except: pass  # If something weird, just skip it\n",
    "    \n",
    "print_list = []\n",
    "\n",
    "# For each PM-Twn-Rng-Sec in defaultdict\n",
    "for section in plss.keys():\n",
    "    # Split the key back up to PM, Twn, Rng, Sec as a list\n",
    "    splits = section.split('-')\n",
    "    \n",
    "    # Count the number of (QQ1, QQ2) tuples associated with each PM/Twn/Rng/Sec\n",
    "    if len(plss[section]) == 16:\n",
    "        # If 16 we have a whole section\n",
    "        # add ['entire', 'section'] to our split list \n",
    "        # queue for writing to csv in print_list\n",
    "        splits.extend(['entire', 'section'])\n",
    "        print_list.append(splits)\n",
    "        # Move on to next section\n",
    "        continue\n",
    "        \n",
    "    # Create another default dictionary init with an empty list \n",
    "    # to sort the quarters individually\n",
    "    quarters = defaultdict(list)\n",
    "    \n",
    "    # quarters are the (QQ1, QQ2) tuples\n",
    "    for quarter in plss[section]:\n",
    "        # Pass to defaultdict with QQ1 as key, QQ2 as the value -> into the \n",
    "        # empty list - create if does not exist, else append QQ2 to list\n",
    "        quarters[quarter[1]].append(quarter)\n",
    "        \n",
    "    # Count the number of QQ2s (q_list) associated with each QQ1 (quarter)\n",
    "    for quarter, q_list in quarters.items():\n",
    "        # if we have 4 we have an entire quarter\n",
    "        if len(q_list) == 4:\n",
    "            splits_ = copy.copy(splits)\n",
    "            # add ['entire', quarter] to a copy of split list \n",
    "            # so we don't step all over our own list (which is iterating above)\n",
    "            # and queue for writing to csv in print_list\n",
    "            splits_.extend(['entire', quarter])\n",
    "            print_list.append(splits_)\n",
    "        else: \n",
    "            # If we don't have all 4 we can't compress - keep them all\n",
    "            for q in q_list:\n",
    "                splits_ = copy.copy(splits)\n",
    "                splits_.extend(q)\n",
    "                print_list.append(splits_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Rows:\n",
      "['6th', '15S', '71W', '1', 'NE', 'NE']\n",
      "['6th', '15S', '71W', '1', 'NW', 'NE']\n",
      "['6th', '15S', '71W', '1', 'SE', 'NE']\n",
      "['6th', '15S', '71W', '1', 'SW', 'NE']\n",
      "['6th', '15S', '71W', '1', 'NE', 'NW']\n",
      "['6th', '15S', '71W', '1', 'NW', 'NW']\n",
      "['6th', '15S', '71W', '1', 'SE', 'NW']\n",
      "['6th', '15S', '71W', '1', 'SW', 'NW']\n",
      "['6th', '15S', '71W', '1', 'NE', 'SE']\n",
      "['6th', '15S', '71W', '1', 'NW', 'SE']\n",
      "['6th', '15S', '71W', '1', 'SE', 'SE']\n",
      "['6th', '15S', '71W', '1', 'SW', 'SE']\n",
      "['6th', '15S', '71W', '1', 'NE', 'SW']\n",
      "['6th', '15S', '71W', '1', 'NW', 'SW']\n",
      "['6th', '15S', '71W', '1', 'SE', 'SW']\n",
      "['6th', '15S', '71W', '1', 'SW', 'SW']\n",
      "['6th', '16S', '71W', '2', 'NE', 'NE']\n",
      "['6th', '16S', '71W', '2', 'NW', 'NE']\n",
      "['6th', '16S', '71W', '2', 'SE', 'NE']\n",
      "['6th', '16S', '71W', '2', 'SW', 'NE']\n",
      "['6th', '16S', '71W', '2', 'NE', 'NW']\n",
      "['6th', '16S', '71W', '2', 'NW', 'NW']\n",
      "['6th', '16S', '71W', '2', 'SE', 'NW']\n",
      "['6th', '16S', '71W', '2', 'SW', 'NW']\n",
      "['6th', '16S', '71W', '2', 'NE', 'SE']\n",
      "['6th', '16S', '71W', '2', 'NW', 'SE']\n",
      "['6th', '16S', '71W', '2', 'SE', 'SE']\n",
      "['6th', '16S', '71W', '2', 'NE', 'SW']\n",
      "['6th', '16S', '71W', '2', 'NW', 'SW']\n",
      "['6th', '16S', '71W', '2', 'SE', 'SW']\n",
      "['6th', '16S', '71W', '2', 'SW', 'SW']\n",
      "\n",
      "Final Rows:\n",
      "['6th', '16S', '71W', '2', 'entire', 'SW']\n",
      "['6th', '16S', '71W', '2', 'entire', 'NE']\n",
      "['6th', '16S', '71W', '2', 'NE', 'SE']\n",
      "['6th', '16S', '71W', '2', 'NW', 'SE']\n",
      "['6th', '16S', '71W', '2', 'SE', 'SE']\n",
      "['6th', '16S', '71W', '2', 'entire', 'NW']\n",
      "['6th', '15S', '71W', '1', 'entire', 'section']\n"
     ]
    }
   ],
   "source": [
    "print 'Source Rows:'\n",
    "for row in source_rows:\n",
    "    print row\n",
    "print\n",
    "print 'Final Rows:'\n",
    "for row in print_list:\n",
    "    print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
